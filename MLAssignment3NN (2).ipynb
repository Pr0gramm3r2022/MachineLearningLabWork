{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NzhJerns5TUJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import cv2\n",
        "import torch, torch.nn as nn\n",
        "import torchvision\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93PpEEMAxXr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lL0UueYrWnJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "# import some data\n",
        "iris = datasets.load_iris()\n",
        "#retrieve the data\n",
        "x = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "MKLZjn6V6WOi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get input classes of the dataset\n",
        "print(iris)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Oki0Ru7Std",
        "outputId": "5782a8a7-b037-41c2-913b-50bef8ccc23b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.6, 1.4, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "irisDf = pd.DataFrame(iris.data, columns=iris.feature_names)\n"
      ],
      "metadata": {
        "id": "8oHYSvygWZ32"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(irisDf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTclcFeqXsRi",
        "outputId": "56b17874-1816-4796-deaa-81dfd108c23b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                  5.1               3.5                1.4               0.2\n",
            "1                  4.9               3.0                1.4               0.2\n",
            "2                  4.7               3.2                1.3               0.2\n",
            "3                  4.6               3.1                1.5               0.2\n",
            "4                  5.0               3.6                1.4               0.2\n",
            "..                 ...               ...                ...               ...\n",
            "145                6.7               3.0                5.2               2.3\n",
            "146                6.3               2.5                5.0               1.9\n",
            "147                6.5               3.0                5.2               2.0\n",
            "148                6.2               3.4                5.4               2.3\n",
            "149                5.9               3.0                5.1               1.8\n",
            "\n",
            "[150 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "UTQ1skfkyRyV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = irisDf[:-1]\n",
        "y = irisDf[:-1]"
      ],
      "metadata": {
        "id": "zzlQ0UihHeZX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
      ],
      "metadata": {
        "id": "ooAtEI-QGoyA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "lvDehe0LUAge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a multiclass cross entopy loss function or a basic MSE function.\n",
        "def Multiclass_Cross_Entropy_Loss(y, m, i, x):\n",
        "    def sigmoid(y):\n",
        "      #yhat =\n",
        "          '''the sigmoid is 1 / 1 + np.power(np.e, z)\n",
        "          need to calculate z, and z = w^Tx + b(weighted sum + b)\n",
        "          need to calculate the weighted sum(the inputs need to pass)\n",
        "          through the network to the output layer, and then we can pass values\n",
        "          z though the sigmoid funtion. But yhat is also equal to the\n",
        "          output, so do are x and yhat different, do I have to differentiate them,\n",
        "          or are they one and the same.'''\n",
        "\n",
        "\n",
        "          costFunction = -1/m * np.sum(np.power(y, i) * np.log())\n",
        "          return 1 / 1 + np.power(np.e, )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Owz7MMpU6mCj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L3KWuihsT_L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#need a method to generate the weights. use a loss function to generate the weights\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 3),  # 4 inputs, 3 outputs\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(3, 2)   # 3 inputs, 2 outputs\n",
        ")\n",
        "\n",
        "# Print the initial weights\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name} initialized with:\\n{param.data}\\n\")"
      ],
      "metadata": {
        "id": "3xrMFPavxY_k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for backpropogation, using SGD. send batches of data through the network\n",
        "#z is the individual outputs from each of the layers, yhat is the total sum of all weights and biases computed at the output\n",
        "#this will be used to calculate the loss, then the gradient(vector of partial derivatives with respect to all the individual parameters)\n",
        "#will be calculated in backprogogation. since the data is being processed in batches, that makes it stochastic\n",
        "#what do we do with the values collected in those batches?\n",
        "'''\n",
        "Gradients are computed layer by layer, starting from the output and moving backward (using the chain rule).\n",
        "Each layer receives gradients from the next layer and computes its own weight gradients.\n",
        "The gradients are not treated as inputs but are stored in tensor.grad for updating weights.\n",
        "'''\n",
        "\n",
        "'''\n",
        "update weights formula: weight = weight - learningRate * derivative of loss/derivative of the weight (which is the partial derivative\n",
        "of the loss with respect to that weight)\n",
        "'''\n"
      ],
      "metadata": {
        "id": "bpkCR0qxxzgy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5828b900-310d-4b2c-fdc0-1445b63fc870"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nupdate weights formula: weight = weight - learningRate * derivative of loss/derivative of the weight (which is the partial derivative\\nof the loss with respect to that weight)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target  # Features and labels\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Define the neural network using Logistic Regression (Sigmoid) activation in the hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)  # Hidden layer\n",
        "        self.sigmoid = nn.Sigmoid()  # Logistic (sigmoid) activation\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)  # Output layer (raw logits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sigmoid(self.hidden(x))  # Apply logistic activation\n",
        "        x = self.output(x)  # Output logits (no softmax)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = NeuralNet(input_dim=4, hidden_dim=4, output_dim=3)\n",
        "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss for multi-class classification\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # Using SGD with momentum\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)  # Forward pass\n",
        "    loss = criterion(outputs, y_train_tensor)  # Compute loss\n",
        "    loss.backward()  # Backpropagation\n",
        "    optimizer.step()  # Update weights\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    y_pred_labels = torch.argmax(y_pred, dim=1)  # Get predicted class labels\n",
        "    accuracy = (y_pred_labels.eq(y_test_tensor).sum() / y_test_tensor.shape[0]).item()\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "0JCPwLU63DY5",
        "outputId": "0a7f9d8a-d2dd-42c6-a7cd-fc0f02b3f0d1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Number of informative, redundant and repeated features must sum to less than the number of total features",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-01f9bd987c85>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Generate a synthetic dataset with 3 classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/datasets/_samples_generator.py\u001b[0m in \u001b[0;36mmake_classification\u001b[0;34m(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, n_clusters_per_class, weights, flip_y, class_sep, hypercube, shift, scale, shuffle, random_state)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;31m# Count features, clusters and samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_informative\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_redundant\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_repeated\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;34m\"Number of informative, redundant and repeated \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;34m\"features must sum to less than the number of total\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of informative, redundant and repeated features must sum to less than the number of total features"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from keras.datasets import cifar10\n",
        "from keras.utils.np_utils import to_categorical\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()'''"
      ],
      "metadata": {
        "id": "L9V9YZcKGnl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN work"
      ],
      "metadata": {
        "id": "1uHwiFKGXt4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "'''transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1,1]\n",
        "\n",
        "])'''\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize 32x32 â†’ 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
        "])\n",
        "'''will turn the data into tensors. for example: if a dataset is labeled x,\n",
        "to turn x into a tensor it will be x.transform since the transform\n",
        "was defined to turn data into a tensor in this .Compose method call here.'''\n",
        "# Download and load CIFAR-10\n",
        "#split the dataset from pytorch\n",
        "\n",
        "#was previously called trainset\n",
        "dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "#testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_size = int(0.7 * len(dataset)) #70% for training\n",
        "valSize = len(dataset) - train_size #30% for testing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtv_frwhQCh4",
        "outputId": "97fb0abf-c342-4599-e110-1e65a71cf43a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n"
      ],
      "metadata": {
        "id": "4AxTyfBsXu08"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "\n",
        "resnet = models.resnet50(pretrained = False)\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "#trainTensor = torch.toTensor(train_size)\n",
        "#TODO -- define your input to the model\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, valSize])\n",
        "\n",
        "#replace this line\n",
        "#split the data 70/30 test train and read in data as a tensor\n",
        "\n",
        "input_tensor = 0\n",
        "\n",
        "trainLoader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "valLoader = DataLoader(val_dataset, batch_size = 32, shuffle = False)\n",
        "\n",
        "#to perform a forward pass\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n",
        "\n",
        "# Forward pass\n",
        "\n",
        "\n",
        "#modifies the final fully connected (FC) layer\n",
        "model.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
        "\n",
        "for images, labels in trainLoader:\n",
        "    outputs = resnet(images)\n",
        "    break\n",
        "outputs = resnet(images)\n",
        "\n",
        "print(outputs.shape)\n",
        "\n",
        "#output = model(input_tensor)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbZSJeuGZdtz",
        "outputId": "e1a23996-0a4b-44c9-938c-71add7516961"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in trainLoader:\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()       # Clear previous gradients\n",
        "        outputs = model(images)     # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()             # Backpropagation\n",
        "        optimizer.step()            # Update weights\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")  # Print loss after each epoch\n",
        "\n",
        "print(\"Training complete! ðŸŽ¯\")"
      ],
      "metadata": {
        "id": "4QiLbl0Sxv29"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}